{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "st68UQlwQlq0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime as dt\n",
        "from datetime import timedelta\n",
        "import functools\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from time import sleep\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8t59oCWQlq1",
        "outputId": "ac42642a-9a6c-41df-ba77-6b42fb84c2d9"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "ROOT = '../'\n",
        "sys.path.append(ROOT)  # Add the root folder to the sys.path\n",
        "\n",
        "# Import the modules\n",
        "from config import *\n",
        "\n",
        "# Reload the configuration\n",
        "from importlib import reload\n",
        "reload(sys.modules['config'])\n",
        "\n",
        "# Import the reloaded modules\n",
        "from config import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Blockchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "timespan = \"10years\" # Default: TIMESPAN | Max: \"10years\" \n",
        "end_date = dt.strptime(END_DATE, \"%Y-%m-%d\")\n",
        "start_date = dt.strptime(\"2011-02-28\", \"%Y-%m-%d\") # Default: dt.strptime(START_DATE, \"%Y-%m-%d\")\n",
        "\n",
        "# Add one year to the end date to make sure we get all the data\n",
        "limit = (end_date - start_date).days + relativedelta(years=1).days # Default: (end_date - start_date).days + relativedelta(years=1).days\n",
        "\n",
        "print(\"Start date: \", start_date)\n",
        "print(\"End date: \", end_date)\n",
        "print(\"Timespan: \", timespan)\n",
        "print(\"Limit: \", limit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metrics considered\n",
        "metrics = [\n",
        "          # Block Details\n",
        "          \"blocks-size\",\n",
        "          \"avg-block-size\",\n",
        "          \"n-transactions-total\",\n",
        "          \"n-transactions-per-block\",\n",
        "\n",
        "          # Mining Information\n",
        "          \"hash-rate\",\n",
        "          \"difficulty\",\n",
        "          \"miners-revenue\",\n",
        "          \"transaction-fees-usd\",\n",
        "\n",
        "          # Network Activity\n",
        "          \"n-unique-addresses\",\n",
        "          \"n-transactions\",\n",
        "          \"estimated-transaction-volume-usd\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "def blockchain_data_crawler(timespan, metric, start):\n",
        "    # API info\n",
        "    url = f'https://api.blockchain.info/charts/{metric}?timespan={timespan}&start={start}&format=csv'\n",
        "\n",
        "    # Obtain data\n",
        "    data = pd.read_csv(url, names=['timestamp', metric])\n",
        "\n",
        "    # Transform \"timestamp\" to datetime type\n",
        "    data['timestamp'] = pd.to_datetime(data[\"timestamp\"])\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge the data\n",
        "merge = functools.partial(pd.merge, on='timestamp')\n",
        "\n",
        "# Gain blockchain data from Blockchain.com API\n",
        "blockchain_data_raw = functools.reduce(merge, [blockchain_data_crawler(timespan, metric, start_date.strftime('%Y-%m-%d')) for metric in metrics])\n",
        "blockchain_data_raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If the data is not complete, we need to get the rest of the data (until the end date)\n",
        "if blockchain_data_raw['timestamp'].iloc[-1] < end_date:\n",
        "    # Get the last timestamp\n",
        "    last_timestamp = blockchain_data_raw['timestamp'].iloc[-1]\n",
        "\n",
        "    # Get the rest of the data from the last timestamp until the end date\n",
        "    blockchain_data_rest = functools.reduce(merge, [blockchain_data_crawler(timespan, metric, last_timestamp.strftime('%Y-%m-%d')) for metric in metrics])\n",
        "\n",
        "    # Concatenate the data\n",
        "    blockchain_data = pd.concat([blockchain_data_raw, blockchain_data_rest])\n",
        "else:\n",
        "    blockchain_data = blockchain_data_raw\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "blockchain_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the dates\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(blockchain_data['timestamp'], blockchain_data['n-transactions'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select only the data from 2016 onwards\n",
        "blockchain_data = blockchain_data[blockchain_data['timestamp'] >= '2016-01-01'].reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the dates\n",
        "plt.plot(blockchain_data['timestamp'], blockchain_data['n-transactions'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "blockchain_data_1_copy = blockchain_data.copy()\n",
        "\n",
        "# Convert the timestamp column to datetime format\n",
        "blockchain_data_1_copy['timestamp'] = pd.to_datetime(blockchain_data_1_copy['timestamp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check duplicated rows on timestamp column\n",
        "duplicated_rows = blockchain_data_1_copy[blockchain_data_1_copy.duplicated(subset=['timestamp'], keep=False)]\n",
        "print(\"Number of duplicated rows: \", duplicated_rows.shape[0])\n",
        "\n",
        "# Drop duplicated rows\n",
        "blockchain_data_1_copy = blockchain_data_1_copy.drop_duplicates(subset=['timestamp'], keep='first')\n",
        "blockchain_data_1_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check missing values\n",
        "missing_values = blockchain_data_1_copy.isnull().sum()\n",
        "print(\"Missing values: \", missing_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieving market capitalization and total circulating data\n",
        "metrics = [\n",
        "          # Currency Statistics\n",
        "          \"total-bitcoins\",\n",
        "          \"market-cap\",\n",
        "  ]\n",
        "\n",
        "blockchain_data_raw = functools.reduce(merge, [blockchain_data_crawler(timespan, metric, start_date.strftime('%Y-%m-%d')) for metric in metrics])\n",
        "blockchain_data_raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If the data is not complete, we need to get the rest of the data (until the end date)\n",
        "if blockchain_data_raw['timestamp'].iloc[-1] < end_date:\n",
        "    # Get the last timestamp\n",
        "    last_timestamp = blockchain_data_raw['timestamp'].iloc[-1]\n",
        "\n",
        "    # Get the rest of the data\n",
        "    blockchain_data_rest = functools.reduce(merge, [blockchain_data_crawler(timespan, metric, last_timestamp.strftime('%Y-%m-%d')) for metric in metrics])\n",
        "\n",
        "    # Concatenate the data\n",
        "    blockchain_data = pd.concat([blockchain_data_raw, blockchain_data_rest])\n",
        "else:\n",
        "    blockchain_data = blockchain_data_raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "blockchain_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the dates\n",
        "plt.plot(blockchain_data['timestamp'], blockchain_data['market-cap'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "blockchain_data_2_copy = blockchain_data.copy()\n",
        "\n",
        "# Extract the date part (year-month-day) and convert it to datetime format\n",
        "blockchain_data_2_copy['timestamp'] = blockchain_data_2_copy['timestamp'].dt.date\n",
        "blockchain_data_2_copy['timestamp'] = pd.to_datetime(blockchain_data_2_copy['timestamp'])\n",
        "blockchain_data_2_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check duplicated rows on timestamp column\n",
        "duplicated_rows = blockchain_data_2_copy[blockchain_data_2_copy.duplicated(subset=['timestamp'], keep=False)]\n",
        "print(\"Number of duplicated rows: \", duplicated_rows.shape[0])\n",
        "\n",
        "# Drop duplicated rows\n",
        "blockchain_data_2_copy = blockchain_data_2_copy.drop_duplicates(subset=['timestamp'], keep='first')\n",
        "blockchain_data_2_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check missing values\n",
        "missing_values = blockchain_data_2_copy.isnull().sum()\n",
        "print(\"Missing values: \", missing_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge all data\n",
        "blockchain_data = pd.merge(blockchain_data_1_copy, blockchain_data_2_copy, how=\"left\", on='timestamp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "blockchain_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check missing values\n",
        "blockchain_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate the daily and hourly datasets\n",
        "start_date = blockchain_data['timestamp'].iloc[0] # Default: START_DATE\n",
        "blockchain_daily = pd.date_range(start=start_date, end=END_DATE, freq='D').to_frame(index=False, name='timestamp')\n",
        "blockchain_hourly = pd.date_range(start=start_date, end=END_DATE, freq='h').to_frame(index=False, name='timestamp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "blockchain_daily"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# blockchain_hourly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge all data with the daily and hourly datasets\n",
        "blockchain_data_daily = pd.merge(blockchain_daily, blockchain_data, how=\"left\", on='timestamp')\n",
        "# blockchain_data_hourly = pd.merge(blockchain_hourly, blockchain_data, how=\"left\", on='timestamp')\n",
        "\n",
        "# Fill missing values with the previous value\n",
        "blockchain_data_daily = blockchain_data_daily.fillna(method='ffill')\n",
        "# blockchain_data_hourly = blockchain_data_hourly.fillna(method='ffill')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "blockchain_data_daily"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# blockchain_data_hourly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the data to a CSV file\n",
        "output_file = os.path.join(ROOT, PRICE_BLOCKCHAIN_DATASET_PATH, \"blockchain_daily.csv\")\n",
        "blockchain_data_daily.to_csv(output_file, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Plot the data\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
        "# ax.plot(blockchain_data_upsampled['timestamp'], blockchain_data_upsampled['market-cap'], label='Market Cap')\n",
        "# ax.set_title('Market Capitalization')\n",
        "# ax.set_xlabel('Date')\n",
        "# ax.set_ylabel('Market Cap')\n",
        "# ax.legend()\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Save the data to a CSV file\n",
        "# output_file = os.path.join(ROOT, PRICE_BLOCKCHAIN_DATASET_PATH, \"blockchain_hourly.csv\")\n",
        "# blockchain_data_hourly.to_csv(output_file, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OHLCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime\n",
        "import calendar\n",
        "import requests\n",
        "import pandas as pd\n",
        "import os.path\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the data to a CSV file\n",
        "output_file = os.path.join(ROOT, PRICE_BLOCKCHAIN_DATASET_PATH, 'ohlcv_noheader.csv')\n",
        "\n",
        "if (os.path.isfile(output_file)): #if the file already exists start from the latest date\n",
        "    starttime = datetime.datetime.fromtimestamp(int(str(int(pd.read_csv(output_file, header=None).iloc[-1][0]))[:-3])) # read the last timestamp for csv file. Bitstamp takes and returs date date with 3 extra zeros. So that\n",
        "else:\n",
        "    start_date = \"2016-01-01\" # Default: START_DATE \n",
        "    starttime = datetime.datetime.strptime(start_date, '%Y-%m-%d') #Start collecting from start_date\n",
        "\n",
        "start_unixtime = calendar.timegm(starttime.utctimetuple())\n",
        "\n",
        "latest_time = int(time.time() - 60 * 60 * 24) #The real ending time. Collect data from starttime to current time - 24 hours\n",
        "\n",
        "track_time = time.time() #because bitstamp only allows 10 requests per minute. Take rest if we are faster than that\n",
        "count = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "while (start_unixtime < latest_time):\n",
        "    end_unixtime = start_unixtime + 60*60*24*30 # 30 days at a time\n",
        "    \n",
        "    if (end_unixtime > latest_time):\n",
        "        end_unixtime = latest_time # If the time is in future.\n",
        "\n",
        "    url = 'https://api.bitfinex.com/v2/candles/trade:1h:tBTCUSD/hist?start={}&end={}&limit=1000'.format(str(start_unixtime) + \"000\", str(end_unixtime) + \"000\") # 1 hour can be changed to any timeframe\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "\n",
        "    ohlcv_data_raw = pd.DataFrame(data).set_index(0).sort_index() # Set the date column as index and sort all data\n",
        "\n",
        "    ohlcv_data_raw.to_csv(output_file, header=None,mode='a') # Append the data\n",
        "    \n",
        "    print('Saved till {}'.format(datetime.datetime.fromtimestamp(int(end_unixtime)).strftime('%Y-%m-%d %H:%M:%S')))\n",
        "    \n",
        "    start_unixtime = end_unixtime + 60 * 60 # To prevent duplicates\n",
        "    count = count + 1\n",
        "    \n",
        "    if (count == 10): # If 10 requests are made\n",
        "        count = 0 # Reset it\n",
        "        \n",
        "        diff = time.time() - track_time\n",
        "        \n",
        "        if (diff <= 60):\n",
        "            print('Sleeping for {} seconds'.format(str(60 - diff)))\n",
        "            time.sleep(60 - diff) #sleep\n",
        "            \n",
        "        \n",
        "        track_time = time.time()\n",
        "    # Bitstamp limits to 10 requests per minute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ohlcv_data_raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add the header\n",
        "ohlcv_data_raw = pd.read_csv(output_file, header=None, index_col=None)\n",
        "\n",
        "ohlcv_data = ohlcv_data_raw.copy()\n",
        "ohlcv_data.columns = ['timestamp', 'open', 'close', 'high', 'low', 'volume']\n",
        "ohlcv_data.set_index('timestamp') \n",
        "\n",
        "# Convert unix into %Y-%m-%d %H:%M:%S format\n",
        "ohlcv_data['timestamp'] = pd.to_datetime(ohlcv_data['timestamp'], unit='ms')\n",
        "ohlcv_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check missing values\n",
        "missing_values = ohlcv_data.isnull().sum()\n",
        "print(\"Missing values: \", missing_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check duplicated rows on timestamp column\n",
        "duplicated_rows = ohlcv_data[ohlcv_data.duplicated(subset=['timestamp'], keep=False)]\n",
        "print(\"Number of duplicated rows: \", duplicated_rows.shape[0])\n",
        "\n",
        "# Drop duplicated rows\n",
        "ohlcv_data = ohlcv_data.drop_duplicates(subset=['timestamp'], keep='first')\n",
        "ohlcv_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crop the data from START_DATE to END_DATE\n",
        "# ohlcv_data = ohlcv_data[(ohlcv_data['timestamp'] >= START_DATE) & (ohlcv_data['timestamp'] <= END_DATE)]\n",
        "# ohlcv_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the timestamp as the index\n",
        "ohlcv_data = ohlcv_data.set_index('timestamp', drop=False)\n",
        "\n",
        "ohlcv_data_downsampled = ohlcv_data.resample('1d').ffill()\n",
        "ohlcv_data_downsampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the data to a CSV file\n",
        "output_file = os.path.join(ROOT, PRICE_BLOCKCHAIN_DATASET_PATH, 'ohlcv_daily.csv')\n",
        "ohlcv_data_downsampled.to_csv(output_file, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ohlcv_data_upsampled = ohlcv_data.resample('1h').ffill()\n",
        "# ohlcv_data_upsampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Plot the data\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.figure(figsize=(14, 7))\n",
        "# plt.plot(ohlcv_data['timestamp'], ohlcv_data['close'])\n",
        "# plt.title(\"BTC/USDT Close Price\")\n",
        "# plt.xlabel(\"Date\")\n",
        "# plt.ylabel(\"Price (USDT)\")\n",
        "# plt.grid()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Save the data to a CSV file\n",
        "# output_file = os.path.join(ROOT, PRICE_BLOCKCHAIN_DATASET_PATH, 'ohlcv_hourly.csv')\n",
        "# ohlcv_data_upsampled.to_csv(output_file, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Merge data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "blockchain_daily = pd.read_csv(os.path.join(ROOT, PRICE_BLOCKCHAIN_DATASET_PATH, 'blockchain_daily.csv'))\n",
        "ohlcv_daily = pd.read_csv(os.path.join(ROOT, PRICE_BLOCKCHAIN_DATASET_PATH, 'ohlcv_daily.csv'))\n",
        "\n",
        "# ohlcv_hourly = pd.read_csv(os.path.join(ROOT, PRICE_BLOCKCHAIN_DATASET_PATH, 'ohlcv_hourly.csv'))\n",
        "# blockchain_hourly = pd.read_csv(os.path.join(ROOT, PRICE_BLOCKCHAIN_DATASET_PATH, 'blockchain_hourly.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "blockchain_daily"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ohlcv_daily"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make sure that the timestamp column format is the same in both datasets\n",
        "blockchain_daily['timestamp'] = pd.to_datetime(blockchain_daily['timestamp'])\n",
        "ohlcv_daily['timestamp'] = pd.to_datetime(ohlcv_daily['timestamp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge ohlcv and blockchain data\n",
        "merged_daily = pd.merge(ohlcv_daily, blockchain_daily, how=\"inner\", on='timestamp')\n",
        "# merged_hourly = pd.merge(ohlcv_hourly, blockchain_hourly, how=\"inner\", on='timestamp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_daily"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# merged_hourly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check duplicates\n",
        "merged_daily[merged_daily.duplicated(subset=['timestamp'], keep=False)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check missing values\n",
        "merged_daily.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the data to a CSV file\n",
        "output_file = os.path.join(ROOT, PRICE_BLOCKCHAIN_DATASET_PATH, \"price_blockchain_daily.csv\")\n",
        "merged_daily.to_csv(output_file, index=False)\n",
        "\n",
        "# output_file = os.path.join(ROOT, PRICE_BLOCKCHAIN_DATASET_PATH, \"price_blockchain_hourly.csv\")\n",
        "# merged_hourly.to_csv(output_file, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
